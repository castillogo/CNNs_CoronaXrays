{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras\n",
    "- As of April 2020, we recommend using Keras **through** Tensorflow, i.e. ``import tensorflow.keras``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 steps:\n",
    "- which model you want\n",
    "    - e.g. architecture, how many neurons, layers, which activation functions, etc.\n",
    "- complile the model\n",
    "    - specify the optimizers, metrics, loss function\n",
    "- then fit the model\n",
    "    - specify epochs (number of iterations of the dataset in backpropagation)and batch size (the data is fed in layers / batches; not all at once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "4/4 [==============================] - 0s 12ms/sample - loss: 0.1427 - acc: 1.0000\n",
      "[0.14267781376838684, 1.0]\n",
      "[[0.13714878]\n",
      " [0.82563996]\n",
      " [0.90951204]\n",
      " [0.12781586]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "#The XOR problem!\n",
    "X = np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]], dtype=np.float64)\n",
    "y = np.array([0.0, 1.0, 1.0, 0.0], dtype=np.float64)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(2, input_shape=(2,)),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "#2 layers network, the first layer consists of 2 neurons, and the second (last) consists of 1.\n",
    "#if your output has N dimensions/rows, then the number of neurons in the output layer must also be N!\n",
    "\n",
    "#input shape is SUPER IMPORTANT. tells Keras what the input shape is, as a tuple. It is the shape of a SINGLE\n",
    "#DATA POINT. The network doesn't care how many data points it receives (it's going to get different number of data\n",
    "#points among trainig and testing, anyways)\n",
    "\n",
    "#the dense layers get their biases automatically. Keras handles this for us. weights are also initialized automatically,\n",
    "#unless, of course, you want to overwrite it with a hyperparameter.\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#the complicated step. Conceptually very new. This is where it actually communicates with TensorFlow\n",
    "#and creates what's called a 'computation graph' -- something that Keras needs to run the model. Keras is compiling\n",
    "#our model into a very abstract form that is implemented in C++.\n",
    "#include metrics = ['accuracy'] to give you accuracy during the epoch\n",
    "\n",
    "\n",
    "#one caveat about compile -- if you run this piece of code more than once in a single session, Keras will get confused.\n",
    "#running Keras in Jupyter is fine, but do this:\n",
    "#from tensforflow.keras import backend as K\n",
    "#K.clear_session() . and you should do this everytime you use Keras, because it will clear the memory\n",
    "#of the previously compiled model every time.\n",
    "\n",
    "model.fit(X, y, epochs=5000, batch_size=4, verbose=0)\n",
    "# verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "# 5000 epochs is obviously overkill for such a small data size, but this will become important with larger data sets \n",
    "\n",
    "\n",
    "#batch sizes here don't have to be the same size\n",
    "score = model.evaluate(X, y, batch_size=4)\n",
    "print(score)\n",
    "\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some useful features:\n",
    "- model.summary() provides a really good overview of the model after you compile it.\n",
    "- you can save and load models to JSON files using the h5py library (copy from class example)\n",
    "- you can look at the model weights with model.get_weights()\n",
    "    - but this is more interesting to look at within *TensorBoard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5.7002287,  4.360515 ],\n",
       "        [-5.262735 , -4.3788095]], dtype=float32),\n",
       " array([ 3.1496096, -2.4337506], dtype=float32),\n",
       " array([[-5.2985444],\n",
       "        [ 4.558196 ]], dtype=float32),\n",
       " array([2.8740137], dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Keras model as a JSON file (containing the structure) and a H5 file (containing the parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the contents of the h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['activation', 'activation_1', 'dense', 'dense_1']>\n",
      "\n",
      "['activation', 'activation_1', 'dense', 'dense_1']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = \"model.h5\"\n",
    "h5 = h5py.File(filename,'r')\n",
    "\n",
    "# List all groups\n",
    "print(\"Keys: {}\\n\".format(h5.keys()))\n",
    "group_keys = list(h5.keys())\n",
    "print(group_keys)\n",
    "\n",
    "# Get the data\n",
    "# data = list(h5[a_group_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MNIST dataset: Guiding principles:\n",
    "- Flatten the X data to be an array of shape (N, 784).\n",
    "- This means that each incoming data point into the network (i.e. input shape) should be shaped ``(784, )``\n",
    "- You will also have to one-hot encode the ylabels. You can use keras' ``to_categorical()`` function for this.\n",
    "- This is a multi-class classification problem, so how many neurons should you have in the final layer? And which activation function should it be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the numbers represent?\n",
    "- **60,000** images (Numpy Arrays), where each image has\n",
    "- **28** rows (i.e. height), and \n",
    "- **28** columns (i.e. width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train is a *vector*, as it only contains 1-dimension; just a long sequence of 60,000 numbers\n",
    "- in other word, it doesn't have \"columns\" since it's not a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
